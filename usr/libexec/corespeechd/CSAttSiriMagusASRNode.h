//
//     Generated by classdump-c 4.2.0 (64 bit).
//
//  Copyright (C) 1997-2019 Steve Nygard. Updated in 2022 by Kevin Bradley.
//

#import <objc/NSObject.h>

@class CSAsset, CSAttSiriAttendingAudioSrcNode, CSAttSiriAudioSrcNode, CSAttSiriController, CSAttSiriEndpointerNode, CSAttSiriUresNode, CSCachedASRResults, CSPlainAudioFileWriter, NSArray, NSString;
@protocol CSAttSiriMagusAsrNodeDelegate, CoreEmbeddedSpeechRecognizerProvider, OS_dispatch_queue;

@interface CSAttSiriMagusASRNode : NSObject
{
    _Bool _isReady;	// 8 = 0x8
    _Bool _shouldProcessAudio;	// 9 = 0x9
    _Bool _speechHasAcceptedResultCandidate;	// 10 = 0xa
    _Bool _didDetectedEndpoint;	// 11 = 0xb
    _Bool _isFileLoggingEnabled;	// 12 = 0xc
    _Bool _areAsrResultsDeferred;	// 13 = 0xd
    _Bool _lastRequestMitigated;	// 14 = 0xe
    unsigned long long _type;	// 16 = 0x10
    NSArray *_requiredNodes;	// 24 = 0x18
    CSAttSiriController *_attSiriController;	// 32 = 0x20
    NSString *_mhId;	// 40 = 0x28
    CSAsset *prefetchedAsset;	// 48 = 0x30
    CSAttSiriEndpointerNode *_endpointerNode;	// 56 = 0x38
    CSAttSiriUresNode *_uresNode;	// 64 = 0x40
    CSAttSiriAudioSrcNode *_audioSrcNode;	// 72 = 0x48
    CSAttSiriAttendingAudioSrcNode *_attendingAudioSrcNode;	// 80 = 0x50
    NSObject<OS_dispatch_queue> *_queue;	// 88 = 0x58
    id <CoreEmbeddedSpeechRecognizerProvider> _interactiveLocalSpeechRecognizer;	// 96 = 0x60
    id <CoreEmbeddedSpeechRecognizerProvider> _presetLocalSpeechRecognizer;	// 104 = 0x68
    CSCachedASRResults *_cachedASRResults;	// 112 = 0x70
    long long _lastRCId;	// 120 = 0x78
    unsigned long long _eagerResultId;	// 128 = 0x80
    double _processedAudioDurationInMillisec;	// 136 = 0x88
    NSString *_requestId;	// 144 = 0x90
    CSPlainAudioFileWriter *_audioFileWriter;	// 152 = 0x98
    id <CSAttSiriMagusAsrNodeDelegate> _delegate;	// 160 = 0xa0
}

- (void).cxx_destruct;	// IMP=0x00200000000f3877
@property(nonatomic) __weak id <CSAttSiriMagusAsrNodeDelegate> delegate; // @synthesize delegate=_delegate;
@property(nonatomic) _Bool lastRequestMitigated; // @synthesize lastRequestMitigated=_lastRequestMitigated;
@property(nonatomic) _Bool areAsrResultsDeferred; // @synthesize areAsrResultsDeferred=_areAsrResultsDeferred;
@property(nonatomic) _Bool isFileLoggingEnabled; // @synthesize isFileLoggingEnabled=_isFileLoggingEnabled;
@property(retain, nonatomic) CSPlainAudioFileWriter *audioFileWriter; // @synthesize audioFileWriter=_audioFileWriter;
@property(retain, nonatomic) NSString *requestId; // @synthesize requestId=_requestId;
@property(nonatomic) _Bool didDetectedEndpoint; // @synthesize didDetectedEndpoint=_didDetectedEndpoint;
@property(nonatomic) double processedAudioDurationInMillisec; // @synthesize processedAudioDurationInMillisec=_processedAudioDurationInMillisec;
@property(nonatomic) _Bool speechHasAcceptedResultCandidate; // @synthesize speechHasAcceptedResultCandidate=_speechHasAcceptedResultCandidate;
@property(nonatomic) _Bool shouldProcessAudio; // @synthesize shouldProcessAudio=_shouldProcessAudio;
@property(nonatomic) unsigned long long eagerResultId; // @synthesize eagerResultId=_eagerResultId;
@property(nonatomic) long long lastRCId; // @synthesize lastRCId=_lastRCId;
@property(retain, nonatomic) CSCachedASRResults *cachedASRResults; // @synthesize cachedASRResults=_cachedASRResults;
@property(retain, nonatomic) id <CoreEmbeddedSpeechRecognizerProvider> presetLocalSpeechRecognizer; // @synthesize presetLocalSpeechRecognizer=_presetLocalSpeechRecognizer;
@property(retain, nonatomic) id <CoreEmbeddedSpeechRecognizerProvider> interactiveLocalSpeechRecognizer; // @synthesize interactiveLocalSpeechRecognizer=_interactiveLocalSpeechRecognizer;
@property(retain, nonatomic) NSObject<OS_dispatch_queue> *queue; // @synthesize queue=_queue;
@property(nonatomic) __weak CSAttSiriAttendingAudioSrcNode *attendingAudioSrcNode; // @synthesize attendingAudioSrcNode=_attendingAudioSrcNode;
@property(nonatomic) __weak CSAttSiriAudioSrcNode *audioSrcNode; // @synthesize audioSrcNode=_audioSrcNode;
@property(nonatomic) __weak CSAttSiriUresNode *uresNode; // @synthesize uresNode=_uresNode;
@property(nonatomic) __weak CSAttSiriEndpointerNode *endpointerNode; // @synthesize endpointerNode=_endpointerNode;
@property(retain, nonatomic) CSAsset *prefetchedAsset; // @synthesize prefetchedAsset;
@property(retain, nonatomic) NSString *mhId; // @synthesize mhId=_mhId;
@property(nonatomic) __weak CSAttSiriController *attSiriController; // @synthesize attSiriController=_attSiriController;
@property(nonatomic) _Bool isReady; // @synthesize isReady=_isReady;
@property(retain, nonatomic) NSArray *requiredNodes; // @synthesize requiredNodes=_requiredNodes;
@property(readonly, nonatomic) unsigned long long type; // @synthesize type=_type;
- (oneway void)sendSpeechCorrectionInfo:(id)arg1 interactionIdentifier:(id)arg2;	// IMP=0x00100000000f35b0
- (oneway void)resetCacheAndCompileAllAssets;	// IMP=0x00100000000f35aa
- (oneway void)preheatLocalSpeechRecognitionWithLanguage:(id)arg1 source:(unsigned long long)arg2;	// IMP=0x00100000000f35a4
- (oneway void)resumeLocalRecognitionWithRequestId:(id)arg1 prefixText:(id)arg2 postfixText:(id)arg3 selectedText:(id)arg4;	// IMP=0x00100000000f359e
- (oneway void)pauseLocalSpeechRecognitionForRequestId:(id)arg1;	// IMP=0x00100000000f3598
- (oneway void)stopSpeechRecognitionWithReason:(unsigned long long)arg1 requestId:(id)arg2;	// IMP=0x00100000000f3592
- (oneway void)startSpeechRecognitionResultsWithSettings:(id)arg1;	// IMP=0x00100000000f358c
- (oneway void)disableLocalSpeechRecognitionForRequestId:(id)arg1;	// IMP=0x00100000000f3586
- (void)stop;	// IMP=0x00100000000f3580
- (void)pause;	// IMP=0x00100000000f357a
- (void)start;	// IMP=0x00100000000f3574
- (void)removeReceiver:(id)arg1;	// IMP=0x00100000000f356e
- (void)addReceiver:(id)arg1;	// IMP=0x00100000000f3568
- (id)init;	// IMP=0x00100000000f355a
- (void)attSiriUresNode:(id)arg1 withUresScore:(float)arg2;	// IMP=0x00100000000f34bb
- (id)_createEmptySpeechPackage;	// IMP=0x00100000000f3430
- (void)_reset;	// IMP=0x00100000000f337c
- (void)_forceAcceptResultCandidateWithRcId:(unsigned long long)arg1 featuresToLog:(id)arg2;	// IMP=0x00100000000f3160
- (void)_queryShouldAcceptEagerResultForDuration:(double)arg1 rcId:(unsigned long long)arg2;	// IMP=0x00100000000f2f88
- (id)_speechParametersForMagus:(id)arg1;	// IMP=0x00100000000f2ac1
- (void)_invalidateLocalSpeechRecognizerIfNeeded;	// IMP=0x00100000000f2a13
- (id)_interactiveLocalSpeechRecognizer;	// IMP=0x00100000000f2860
- (void)attSiriNode:(id)arg1 didDetectStartpointAtTime:(double)arg2;	// IMP=0x00100000000f285a
- (void)attSiriNode:(id)arg1 didDetectHardEndpointAtTime:(double)arg2 withMetrics:(id)arg3 usesAutomaticEndPointing:(_Bool)arg4;	// IMP=0x00100000000f278b
- (void)localSpeechRecognizer:(id)arg1 didSelectRecognitionModelWithModelProperties:(id)arg2;	// IMP=0x00100000000f2785
- (void)localSpeechRecognizer:(id)arg1 didProduceEndpointFeaturesWithWordCount:(long long)arg2 trailingSilenceDuration:(long long)arg3 eosLikelihood:(double)arg4 pauseCounts:(id)arg5 silencePosterior:(double)arg6 processedAudioDurationInMilliseconds:(long long)arg7;	// IMP=0x00100000000f26b8
- (void)localSpeechRecognizer:(id)arg1 didCompletionRecognitionWithStatistics:(id)arg2 error:(id)arg3;	// IMP=0x00100000000f25cb
- (void)localSpeechRecognizer:(id)arg1 didRecognizePackage:(id)arg2 withMetadata:(id)arg3;	// IMP=0x00100000000f24c6
- (void)localSpeechRecognizer:(id)arg1 didRecognizePackage:(id)arg2;	// IMP=0x00100000000f2407
- (void)localSpeechRecognizer:(id)arg1 didRecognizeRawEagerRecognitionCandidate:(id)arg2;	// IMP=0x00100000000f2401
- (void)localSpeechRecognizer:(id)arg1 didProcessAudioDuration:(double)arg2;	// IMP=0x00100000000f2364
- (void)localSpeechRecognizer:(id)arg1 didRecognizeTokens:(id)arg2 withMetadata:(id)arg3;	// IMP=0x00100000000f225f
- (void)localSpeechRecognizer:(id)arg1 didRecognizeTokens:(id)arg2;	// IMP=0x00100000000f21a0
- (void)_handleStopSpeechRecognitionTask;	// IMP=0x00100000000f2157
- (void)attSiriAudioSrcNodeDidStop:(id)arg1;	// IMP=0x00100000000f210c
- (void)attSiriAudioSrcNodeLPCMRecordBufferAvailable:(id)arg1 audioChunk:(id)arg2;	// IMP=0x00100000000f207f
- (void)attSiriAudioSrcNodeDidStartRecording:(id)arg1 successfully:(_Bool)arg2 error:(id)arg3;	// IMP=0x00100000000f2031
- (void)deliverCachedASRResultsWithRequestId:(id)arg1 connectionListener:(id)arg2 completion:(CDUnknownBlockType)arg3;	// IMP=0x00100000000f1ea3
- (_Bool)cachedASRResultsAvailable;	// IMP=0x00100000000f1e15
- (void)stopMagusASRProcessing;	// IMP=0x00100000000f1d55
- (void)startMagusASRProcessingWithSetting:(id)arg1 requestId:(id)arg2 completionBlock:(CDUnknownBlockType)arg3;	// IMP=0x00100000000f1c6f
- (void)registerAudioSrcNodeWithType:(unsigned long long)arg1 audioSrcNode:(id)arg2;	// IMP=0x00100000000f1bcf
- (void)dealloc;	// IMP=0x00100000000f1b1b
- (id)initWithEndpointerNode:(id)arg1 uresNode:(id)arg2 targetQueue:(id)arg3 isFileLoggingEnabled:(_Bool)arg4 localSpeechRecognizer:(id)arg5 delegate:(id)arg6;	// IMP=0x00100000000f1939
- (id)initWithEndpointerNode:(id)arg1 uresNode:(id)arg2 targetQueue:(id)arg3 isFileLoggingEnabled:(_Bool)arg4 delegate:(id)arg5;	// IMP=0x00100000000f191d

// Remaining properties
@property(readonly, copy) NSString *debugDescription;
@property(readonly, copy) NSString *description;
@property(readonly) unsigned long long hash;
@property(readonly) Class superclass;

@end

